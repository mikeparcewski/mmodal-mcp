# Base configuration ---------------------------------------------------------
# Use this section to define the default model and authentication settings.

LITELLM_DEFAULT_MODEL="gemini/gemini-1.5-flash"   # Fallback LiteLLM model identifier (provider/model)
LITELLM_DEFAULT_API_KEY="your-api-key-here"       # Default API key passed to LiteLLM
# LITELLM_DEFAULT_API_BASE=""
# LITELLM_DEFAULT_EXTRA_PARAMS='{}'

# Optional per-domain overrides ---------------------------------------------
# Uncomment if you need different credentials/models for image, docs, or text flows.

# LITELLM_IMAGE_MODEL="gemini/gemini-image-001"
# LITELLM_IMAGE_API_KEY=""
# LITELLM_IMAGE_API_BASE=""
# LITELLM_IMAGE_EXTRA_PARAMS='{}'

# LITELLM_DOCS_MODEL="gemini/gemini-2.0-pro"
# LITELLM_DOCS_API_KEY=""
# LITELLM_DOCS_API_BASE=""
# LITELLM_DOCS_EXTRA_PARAMS='{}'

# LITELLM_TEXT_MODEL="gemini/gemini-2.0-pro"
# LITELLM_TEXT_API_KEY=""
# LITELLM_TEXT_API_BASE=""
# LITELLM_TEXT_EXTRA_PARAMS='{}'

# Optional LiteLLM overrides -------------------------------------------------
# Uncomment these if you need to point to a non-default endpoint or pass extra kwargs.

# LITELLM_API_BASE="https://custom-endpoint.googleapis.com"  # Custom API base for enterprise routing
# LITELLM_DEFAULT_EXTRA_PARAMS='{"safetySettings": {"harmCategory": "HARM_CATEGORY_DEROGATORY"}}'
# LITELLM_TEXT_EXTRA_PARAMS='{"response_mime_type": "text/plain"}'

# Prompt customization -------------------------------------------------------

IMAGE_GENERATION_PROMPT_PREFIX="Create an image that follows the user's instructions with attention to visual detail."
ASSET_DESCRIPTION_SYSTEM_PROMPT="You are an attentive analyst who describes visual and document assets for coding assistants."
ASSET_DESCRIPTION_PROMPT_TEMPLATE="Provide a concise yet thorough description of the supplied asset so a coding assistant can reference it. Highlight key structures, notable content, and anything relevant to developers building product experiences."
ASSET_STRUCTURE_GUIDANCE_VISUAL="Include notes about composition, style, color balance, and any focal points."
ASSET_STRUCTURE_GUIDANCE_DOCUMENT="Outline the document layout, hierarchy, and any repeated sections or tables."
ASSET_VALIDATION_SYSTEM_PROMPT="You are a meticulous reviewer who validates whether an asset matches a provided description. Always respond with JSON containing 'verdict', 'confidence', and 'reason'."
ASSET_VALIDATION_PROMPT_TEMPLATE="Determine if the asset aligns with the expected description. Respond with JSON: {\"verdict\": \"pass|fail\", \"confidence\": number or null, \"reason\": string}. If verdict is 'fail', make the reason a checklist of concrete fixes (e.g., '- add the missing red logo above the header')."

# Storage and caching --------------------------------------------------------

IMAGE_DIR="images"            # Folder where generated images + metadata are stored
CACHE_TTL_SECONDS=3600        # Seconds before cached images expire (0 to disable expiry)
CACHE_MAX_ITEMS=256           # Maximum cached images kept in memory (LRU eviction)
FILE_RETENTION_DAYS=7         # Cleanup task removes files older than this (in days)
CLEANUP_CHECK_INTERVAL_SECONDS=60   # Seconds to wait when the image directory is missing
CLEANUP_RUN_INTERVAL_SECONDS=3600   # Seconds between cleanup sweeps
IMAGE_MIN_DIMENSION=64              # Minimum allowed width/height in pixels
IMAGE_MAX_DIMENSION=4096            # Maximum allowed width/height in pixels

# Example: OpenAI DALL-E 3 via LiteLLM ---------------------------------------
# Copy these values into your real .env if you prefer OpenAI.
# LITELLM_DEFAULT_MODEL="openai/dall-e-3"
# LITELLM_DEFAULT_API_KEY="${OPENAI_API_KEY}"
# LITELLM_DEFAULT_API_BASE=""
# LITELLM_DEFAULT_EXTRA_PARAMS='{"quality": "high", "style": "vivid"}'
# LITELLM_TEXT_MODEL="openai/gpt-4o-mini"
# LITELLM_TEXT_EXTRA_PARAMS='{"temperature": 0.4}'

# Example: Local inference server --------------------------------------------
# LITELLM_DEFAULT_MODEL="local/flux-schnell"
# LITELLM_DEFAULT_API_KEY=""                          # Usually not required for local setups
# LITELLM_DEFAULT_API_BASE="http://localhost:8080"    # Point to your local LiteLLM-compatible proxy
# LITELLM_DEFAULT_EXTRA_PARAMS='{"guidance_scale": 7.5}'
# LITELLM_TEXT_MODEL="local/qwen-2"
